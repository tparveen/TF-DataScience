{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments\n",
    "\n",
    "In this assignment, you're required to clean up the two datasets. You'll be using these datasets in the later checkpoints of this module and hence cleaning them up here will help you save time when working with these datasets.\n",
    "\n",
    "The first dataset is a dialogue dataset called Cornell Movie--Dialogs Corpus. This corpus includes conversations between the characters of more than 600 movies.\n",
    "\n",
    "The second dataset is the Twitter US Airline Sentiment dataset from Kaggle. This dataset contains the tweets from travelers about some airlines in February 2015. This dataset is usually used in sentiment analysis but we'll use it for sentence generation later on.\n",
    "\n",
    "Since the memory requirements of the datasets are relatively large, we recommend you to use Google Colaboratory.\n",
    "\n",
    "Please submit your solutions to the following tasks as a link to your Jupyter notebook on GitHub.\n",
    "\n",
    "\n",
    "Submit your work below, and plan on discussing it with your mentor. You can also take a look at this example solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "#!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  The data is in the table called \"dialogs\".\n",
    "### Apply the data preprocessing techniques you learned here to Cornell Movie--Dialogs \n",
    "# Corpus data. You'll be using this dataset when developing a chatbot in a later checkpoint. \n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'cornell_movie_dialogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dialogs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Not the hacking and gagging and spitting part....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Okay... then how 'bout we try out some French ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Forget it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Cameron.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>The thing is, Cameron -- I'm at the mercy of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Seems like she could get a date easy enough...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            dialogs\n",
       "0      0  Can we make this quick?  Roxanne Korrine and A...\n",
       "1      1  Well, I thought we'd start with pronunciation,...\n",
       "2      2  Not the hacking and gagging and spitting part....\n",
       "3      3  Okay... then how 'bout we try out some French ...\n",
       "4      4  You're asking me out.  That's so cute. What's ...\n",
       "5      5                                         Forget it.\n",
       "6      6  No, no, it's my fault -- we didn't have a prop...\n",
       "7      7                                           Cameron.\n",
       "8      8  The thing is, Cameron -- I'm at the mercy of a...\n",
       "9      9     Seems like she could get a date easy enough..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "dialogs_df = pd.read_sql_query('select * from dialogs',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()\n",
    "\n",
    "\n",
    "dialogs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: When parsing the data using SpaCy, you may run into some memory issues even \n",
    "# in Google Colaboratory. If you're having memory issues, try parsing your text as follows:\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# below is necessary to avoid memory error of SpaCy\n",
    "nlp.max_length = 20000000\n",
    "\n",
    "# all the processing work is done below, so it may take a while\n",
    "dialogs_doc = nlp(\" \".join(dialogs_df.dialogs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dialogs_doc object is a <class 'spacy.tokens.doc.Doc'> object.\n",
      "It is 4273815 tokens long\n",
      "The first three tokens are 'Can we make'\n",
      "The type of each token is <class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "# let's explore the objects we've built.\n",
    "print(\"The dialogs_doc object is a {} object.\".format(type(dialogs_doc)))\n",
    "print(\"It is {} tokens long\".format(len(dialogs_doc)))\n",
    "print(\"The first three tokens are '{}'\".format(dialogs_doc[:3]))\n",
    "print(\"The type of each token is {}\".format(type(dialogs_doc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the stopwords\n",
    "dialogs_without_stopwords = [token for token in dialogs_doc if not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "lemmas = [token.lemma_ for token in dialogs_without_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the data preprocessing techniques you learned here to Twitter US Airline Sentiment data. You'll be using this dataset when generating sentences in a later checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  The data is in the table called \"twitter\".\n",
    "###Apply the data preprocessing techniques you learned here to Twitter US Airline Sentiment \n",
    "###data. You'll be using this dataset when generating sentences in a later checkpoint. \n",
    "### You should access the dataset from the Thinkful database using the following credentials:\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'twitter_sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>None</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>None</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>None</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>None</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>570300767074181121</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:14:33 -0800</td>\n",
       "      <td>None</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>570300616901320704</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>cjmcginnis</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:13:57 -0800</td>\n",
       "      <td>San Francisco CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>570300248553349120</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>pilot</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:12:29 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>570299953286942721</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>dhepburn</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 11:11:19 -0800</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>570295459631263746</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>None</td>\n",
       "      <td>YupitsTate</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>None</td>\n",
       "      <td>2015-02-24 10:53:27 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0      0  570306133677760513           neutral                        1.0000   \n",
       "1      1  570301130888122368          positive                        0.3486   \n",
       "2      2  570301083672813571           neutral                        0.6837   \n",
       "3      3  570301031407624196          negative                        1.0000   \n",
       "4      4  570300817074462722          negative                        1.0000   \n",
       "5      5  570300767074181121          negative                        1.0000   \n",
       "6      6  570300616901320704          positive                        0.6745   \n",
       "7      7  570300248553349120           neutral                        0.6340   \n",
       "8      8  570299953286942721          positive                        0.6559   \n",
       "9      9  570295459631263746          positive                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0           None                        NaN  Virgin America   \n",
       "1           None                     0.0000  Virgin America   \n",
       "2           None                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "5     Can't Tell                     0.6842  Virgin America   \n",
       "6           None                     0.0000  Virgin America   \n",
       "7           None                        NaN  Virgin America   \n",
       "8           None                        NaN  Virgin America   \n",
       "9           None                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                   None     cairdin                None              0   \n",
       "1                   None    jnardino                None              0   \n",
       "2                   None  yvonnalynn                None              0   \n",
       "3                   None    jnardino                None              0   \n",
       "4                   None    jnardino                None              0   \n",
       "5                   None    jnardino                None              0   \n",
       "6                   None  cjmcginnis                None              0   \n",
       "7                   None       pilot                None              0   \n",
       "8                   None    dhepburn                None              0   \n",
       "9                   None  YupitsTate                None              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.        None   \n",
       "1  @VirginAmerica plus you've added commercials t...        None   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...        None   \n",
       "3  @VirginAmerica it's really aggressive to blast...        None   \n",
       "4  @VirginAmerica and it's a really big bad thing...        None   \n",
       "5  @VirginAmerica seriously would pay $30 a fligh...        None   \n",
       "6  @VirginAmerica yes, nearly every time I fly VX...        None   \n",
       "7  @VirginAmerica Really missed a prime opportuni...        None   \n",
       "8    @virginamerica Well, I didn't…but NOW I DO! :-D        None   \n",
       "9  @VirginAmerica it was amazing, and arrived an ...        None   \n",
       "\n",
       "               tweet_created    tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800              None  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800              None  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800         Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800              None  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800              None  Pacific Time (US & Canada)  \n",
       "5  2015-02-24 11:14:33 -0800              None  Pacific Time (US & Canada)  \n",
       "6  2015-02-24 11:13:57 -0800  San Francisco CA  Pacific Time (US & Canada)  \n",
       "7  2015-02-24 11:12:29 -0800       Los Angeles  Pacific Time (US & Canada)  \n",
       "8  2015-02-24 11:11:19 -0800         San Diego  Pacific Time (US & Canada)  \n",
       "9  2015-02-24 10:53:27 -0800       Los Angeles  Eastern Time (US & Canada)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "tweets_df = pd.read_sql_query('select * from twitter',con=engine)\n",
    "\n",
    "# no need for an open connection, as we're only doing a single query\n",
    "engine.dispose()\n",
    "\n",
    "\n",
    "tweets_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# below is necessary to avoid memory error of SpaCy\n",
    "nlp.max_length = 20000000\n",
    "\n",
    "# all the processing work is done below, so it may take a while\n",
    "twitter_doc = nlp(\" \".join(tweets_df.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The twitter_doc object is a <class 'spacy.tokens.doc.Doc'> object.\n",
      "It is 307328 tokens long\n",
      "The first three tokens are '@VirginAmerica What @dhepburn'\n",
      "The type of each token is <class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "# let's explore the objects we've built.\n",
    "print(\"The twitter_doc object is a {} object.\".format(type(twitter_doc)))\n",
    "print(\"It is {} tokens long\".format(len(twitter_doc)))\n",
    "print(\"The first three tokens are '{}'\".format(twitter_doc[:3]))\n",
    "print(\"The type of each token is {}\".format(type(twitter_doc[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the stopwords\n",
    "tweets_without_stopwords = [token for token in twitter_doc if not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "lemmas = [token.lemma_ for token in tweets_without_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
