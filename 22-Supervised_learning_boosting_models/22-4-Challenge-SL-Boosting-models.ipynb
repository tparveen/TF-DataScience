{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Which model?\n",
    "\n",
    "You now have a fairly substantial starting toolbox of supervised learning methods that you can use to tackle a host of exciting problems. To make sure all of these ideas are organized in your mind, please go through the list of problems below. \n",
    "\n",
    "For each, identify which supervised learning method(s) would be best for addressing that particular problem. Explain your reasoning and discuss your answers with your mentor.\n",
    "\n",
    "* Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    "\n",
    "    - We are predicting numeric result (running times) with good accuracy from historical data. A good model to use here would be `SL regression - Random Forrest` will give us good accuracy (might be some hit in speed)\n",
    "\n",
    "* You have more features (columns) than rows in your dataset.\n",
    "    - the way I see this is we have a lot of features but not a lot of data (since rows are less (?) ) So PCA would be a good choice to identify the prominent features. \n",
    "    \n",
    "* Identify the most important characteristic predicting likelihood of being jailed before age 20.\n",
    "    - We are identifying features that will result in a categorical outcome `jailed before 20 or not`. These features may not be numberic. This will be a classification model - especifically `logistic regression` - because we are trying to find the contributing factors to the prediction.\n",
    "    \n",
    "* Implement a filter to “highlight” emails that might be important to the recipient\n",
    "    - `Naive Bayes` will be a good choice - outcome is categorical `important or not`. Emails can be large amounts of data. We can classify someting in the email that indicates the outcome.\n",
    "\n",
    "* You have 1000+ features.\n",
    "    - PCA (principal component analysis). we have a wide range of features here\n",
    "    \n",
    "* Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "    - Classification model and use of decision tree - Decision trees are simple and this a simple prediction that does not have a lot of features. So a decision trees will be good.\n",
    "    \n",
    "* Your dataset dimensions are 982400 x 500\n",
    "    - Large dataset - we don't know what type of outcomes we want - so just looking at the size of the dataset, it would be Naive Bayes\n",
    "    \n",
    "* Identify faces in an image.\n",
    "    - SVM fpr classigication or Neural Netorks for classification.\n",
    "    \n",
    "* Predict which of three flavors of ice cream will be most popular with boys vs girls.\n",
    "   - This will be either a decision tree or Random Forrest - possible Random Forrest - we will start building decision tree with very little parameters since we don't have a whole lot then then come to decision about which flavor is desirable with boys vs girls. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
