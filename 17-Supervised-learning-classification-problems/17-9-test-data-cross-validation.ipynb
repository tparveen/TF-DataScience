{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-sample evaluation and cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes: spam filter\n",
    "- building a spam filter\n",
    "- There should be spam/ham labels. In this data this is done for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import necessary files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### # Grab and process the raw data.\n",
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "sms_raw.columns = ['spam', 'message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### lets look at the data\n",
    "sms_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data analysis\n",
    "- we have two columns, a label and a message.\n",
    "- We have to get features from this data.  Now, a message isn't really a feature. However, we can engineer features from the message field relatively easily. This kind of feature engineering is a basic version of what we'll cover in the NLP section.\n",
    "- At the most obvious level, a feature from the message can be whether it contains a given word. These words could be keywords = ['click', 'offer', 'winner', 'buy', 'free', 'cash', 'urgent'] etc.\n",
    "\n",
    "- Let's add those columns to our dataframe. The words chosen below are simply intuited as possibly having something to do with spam. Try some of your own ideas too!\n",
    "- Note that you could add new features to the dataframe simply by adding them to the keywords list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['click', 'offer', 'winner', 'buy', 'free', 'cash', 'urgent']\n",
    "\n",
    "### lets look at the message and see if the message has any of these words. if they do, possibility of spam\n",
    "for key in keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sms_raw[str(key)] = sms_raw.message.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "sms_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data analysis\n",
    "- Another feature option would be if the message is all uppercase. That seems kind of spammy doesn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### is themessage all uppercase?\n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we go further, let's turn the spam column into a boolean so we can easily \n",
    "# do some statistics to prepare for modeling.\n",
    "\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "# Note that if you run this cell a second time everything will become false.\n",
    "# So... Don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes assumptions\n",
    "- Now, as we covered before one of the main assumptions of Naive Bayes is that the variables fed into the model are independent of each other. \n",
    "- Let's check to see how true that is in this case using Pandas' built in correlation matrix function, corr(), and the heatmap from seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(sms_raw.corr(), linewidth=1,annot=True,cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "- Most of the words show strong independence from each other. The only exceptions are free:offer and cash:winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building model: Pick out your training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training data\n",
    "# SKLearn required you to specify an outcome (y or dependent variable) \n",
    "# and your inputs (x or independent variables). \n",
    "# We'll do that below under the titles data and target.\n",
    "\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy of your model here.\n",
    "# Display our results.\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum(),\n",
    "    100*(1-(target != y_pred).sum()/data.shape[0])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use confusion matrix to see FP and FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(target, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use confusion matrix (your own method) to see FP and FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your confusion matrix and calculate sensitivity and specificity here.\n",
    "#cm = [[TN, FP],[FN, TP]] - true negetive, false positive, false negetive, true positive\n",
    "\n",
    "def manually_calculate_cm(test_y, test_predictions):\n",
    "    \"\"\"Manually create confusion matrix by comparing predictions with answers.\"\"\"\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "\n",
    "    x = 0\n",
    "    while x < len(test_y):\n",
    "        if test_y[x] == 0 and test_predictions[x] == 0:\n",
    "            TN += 1\n",
    "        if test_y[x] == 0 and test_predictions[x] == 1:\n",
    "            FP += 1\n",
    "        if test_y[x] == 1 and test_predictions[x] == 1:\n",
    "            TP += 1\n",
    "        if test_y[x] == 1 and test_predictions[x] == 0:\n",
    "            FN += 1\n",
    "        x += 1\n",
    "\n",
    "    cm = [[TN, FP],[FN, TP]]\n",
    "    return cm\n",
    "\n",
    "manual = manually_calculate_cm(target, y_pred)\n",
    "\n",
    "#print(\"\\nsklearn cm:\", data)\n",
    "print(\"Manual:\", manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # Test your model with different holdout groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your model with different holdout groups.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Cross Validation - with multiple holdouts (folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation : your own method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform your additional evaluation here\n",
    " - Using the topics we introduced earlier in this lesson, try to do a more in depth evaluation of the model looking at the kind of errors we're generating and what accuracy we'd get if we just randomly guessed. You may want to use what's known as a confusion matrix to show different kinds of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use confusion matrix again to see FP and FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magda Questions\n",
    "- Do we always crete your own cross validation? if so how?\n",
    "- How do I do additional evaluation here?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
